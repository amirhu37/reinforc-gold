{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {
    "executionInfo": {
     "elapsed": 7952,
     "status": "ok",
     "timestamp": 1684278986482,
     "user": {
      "displayName": "A H Sh",
      "userId": "16181755643368908406"
     },
     "user_tz": -210
    },
    "id": "HY6mx2bIR6Vp"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "\n",
    "from typing import Any, Literal\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "import torch\n",
    "Tensor = torch.Tensor\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_m5 : str = r\"C:\\Users\\Nemo\\Desktop\\sth-financial\\XAUUSDM5.csv\"\n",
    "path_m15: str = r\"C:\\Users\\Nemo\\Desktop\\sth-financial\\XAUUSDM15.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1684278986483,
     "user": {
      "displayName": "A H Sh",
      "userId": "16181755643368908406"
     },
     "user_tz": -210
    },
    "id": "ittlDRFmgXHU",
    "outputId": "860a67e2-52c9-4888-eed0-6450cdd91835"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_m15 , \n",
    "\t\t\t\t   encoding = 'utf-16', \n",
    "\t\t\t\t   names =  ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', '0'] )\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', drop=True, inplace = True)\n",
    "df.drop('0', axis=1)\n",
    "\n",
    "\n",
    "# variables\n",
    "\n",
    "Open_ = df['Open']\n",
    "close = df['Close']\n",
    "# volume = data['Volume']\n",
    "high = df['High']\n",
    "time = df.index\n",
    "\n",
    "Round = 4\n",
    "\n",
    "rsi_len = 14\n",
    "\n",
    "std_len = mean_len = 5\n",
    "\n",
    "Vol_ma_1 = ma_1 = 10\n",
    "\n",
    "Vol_ma_2 = ma_2 = 20\n",
    "\n",
    "\n",
    "# X = df[[ 'change', 'rsi',   'macd' ]]\n",
    "# Y = df[[ 'buy', 'sell']]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = \\\n",
    "# train_test_split( X,\n",
    "#                  Y, \n",
    "#                  test_size= 0.30\n",
    "#                  , shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-04-16 01:00:00</th>\n",
       "      <td>3230.96</td>\n",
       "      <td>3233.35</td>\n",
       "      <td>3229.84</td>\n",
       "      <td>3232.16</td>\n",
       "      <td>482</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-16 01:15:00</th>\n",
       "      <td>3232.15</td>\n",
       "      <td>3235.25</td>\n",
       "      <td>3231.47</td>\n",
       "      <td>3235.25</td>\n",
       "      <td>368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-16 01:30:00</th>\n",
       "      <td>3234.82</td>\n",
       "      <td>3238.90</td>\n",
       "      <td>3234.37</td>\n",
       "      <td>3238.82</td>\n",
       "      <td>733</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-16 01:45:00</th>\n",
       "      <td>3238.76</td>\n",
       "      <td>3242.23</td>\n",
       "      <td>3237.48</td>\n",
       "      <td>3241.47</td>\n",
       "      <td>752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-16 02:00:00</th>\n",
       "      <td>3241.52</td>\n",
       "      <td>3241.74</td>\n",
       "      <td>3238.36</td>\n",
       "      <td>3241.73</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Open     High      Low    Close  Volume  0\n",
       "Date                                                              \n",
       "2025-04-16 01:00:00  3230.96  3233.35  3229.84  3232.16     482  0\n",
       "2025-04-16 01:15:00  3232.15  3235.25  3231.47  3235.25     368  0\n",
       "2025-04-16 01:30:00  3234.82  3238.90  3234.37  3238.82     733  0\n",
       "2025-04-16 01:45:00  3238.76  3242.23  3237.48  3241.47     752  0\n",
       "2025-04-16 02:00:00  3241.52  3241.74  3238.36  3241.73     756  0"
      ]
     },
     "execution_count": 1058,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nX6cOy3AmYh1"
   },
   "source": [
    "#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1684278986483,
     "user": {
      "displayName": "A H Sh",
      "userId": "16181755643368908406"
     },
     "user_tz": -210
    },
    "id": "ejyqd7VtrBxy",
    "outputId": "b9ede333-0d6e-40bd-e455-aaee7cc2a3db"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from typing import Any\n",
    "from numpy import dtype, floating\n",
    "from pandas.core.frame import DataFrame\n",
    "from pandas.core.series import Series\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_RSI(data: Series , time_window : int = 14) -> Series:\n",
    "\t\tdelta: Series[type[float]] = data.diff() # type: ignore\n",
    "\n",
    "\t\tup, down = delta.copy(), delta.copy()\n",
    "\t\tup[up < 0] = 0 # type: ignore\n",
    "\t\tdown[down > 0] = 0 # type: ignore\n",
    "\n",
    "\t\troll_up: Series[float] = up.rolling(time_window).mean()\n",
    "\t\troll_down: Series[float] = down.abs().rolling(time_window).mean()\n",
    "\n",
    "\t\tRS: Series[float] = roll_up / roll_down\n",
    "\t\tRSI: Series[float] = 100.0 - (100.0 / (1.0 + RS))\n",
    "\n",
    "\t\treturn RSI.round(Round)\n",
    "\n",
    "def norming(row : pd.Series, on: str ) -> Literal[1] | Literal[0]:\n",
    "\tif max(row['buy'], row['sell'], row['hold']) == row[on]:\n",
    "\t\treturn 1\n",
    "\telse:\n",
    "\t\treturn 0\n",
    "\n",
    "# def ABS(row : DataFrame ) -> pd.Series:\n",
    "# \tif row['sell']:\n",
    "# \t\treturn row[\"sell\"].abs()\n",
    "# \telse:\n",
    "\t\t# return row['sell']\n",
    "\n",
    "def moving_avg(data : np.ndarray | pd.Series , window_size : int)  :\n",
    "\tif isinstance(data, np.ndarray):\n",
    "\t\treturn np.convolve(data, np.ones(window_size)/window_size, mode='valid').round(Round)\n",
    "\tif isinstance(data, pd.Series):\n",
    "\t\treturn data.rolling(window=window_size, min_periods=1).mean().round(Round)\n",
    "\n",
    "# def macd(data, fast, slow):\n",
    "#     if isinstance(data, np.ndarray):\n",
    "#         ma1 =  np.convolve(data, np.ones(fast)/fast, mode='valid')\n",
    "#         ma2 =  np.convolve(data, np.ones(slow)/slow, mode='valid')\n",
    "#         return ma2 - ma1\n",
    "#     if isinstance(data, pd.Series):\n",
    "#         ma1 =  data.rolling(fast, min_periods=1).mean()\n",
    "#         ma2 =  data.rolling(slow, min_periods=1).mean()\n",
    "#         return ma2 - ma1\n",
    "\n",
    "# def clc_std(series : pd.Series , window: int):\n",
    "#     rolling_std = series.rolling(window=window).std()\n",
    "#     return  rolling_std\n",
    "\n",
    "def clc_mean(series : Series , window: int) :\n",
    "\t\trolling_mean = series.rolling(window=window).mean().round(Round)\n",
    "\t\treturn  rolling_mean\n",
    "\n",
    "def moving_avg_std(series : Series , window : int)  -> Series:\n",
    "\t\"\"\"Calculate the moving average and standard deviation of a pandas series, and then divide the two\"\"\"\n",
    "\trolling_mean = series.rolling(window=window).mean().round(Round)\n",
    "\trolling_std = series.rolling(window=window).std().round(Round)\n",
    "\treturn rolling_mean - rolling_std\n",
    "\t\t\t\t\n",
    "# def lr_schedule_1(epoch, lr):\n",
    "#     if epoch < 3:\n",
    "#         return lr\n",
    "#     else:\n",
    "#         return lr * tf.math.exp(-0.1)\n",
    "\n",
    "# def lr_schedule_2(epoch, lr, decay_rate=0.5, decay_steps = 3 ):\n",
    "#     return lr * decay_rate**(np.floor(epoch / decay_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1684278986483,
     "user": {
      "displayName": "A H Sh",
      "userId": "16181755643368908406"
     },
     "user_tz": -210
    },
    "id": "3xhWTHEyrBxy"
   },
   "outputs": [],
   "source": [
    "def creat_data(df: pd.DataFrame):\n",
    "\tdf['diff']  = round( df['High'] - df['Open'] , Round )\n",
    "\tdf['cadle-type']  = (df['Close'] - df['Open']).round(Round)\n",
    "\tdf['hike'] = df['diff'] / df['cadle-type']\n",
    "\tdf['change']  =  df['Open'] - moving_avg(df['Open'], ma_1 ) \n",
    "\n",
    "\tdf['percent']  =  (close - df['Open']) / close  * 100\n",
    "\n",
    "\tdf['rsi']  = calculate_RSI( df['Open'] , rsi_len ) / 100\n",
    "\n",
    "\t# df['std'] = Std = round(std(df['Open'] , std_len), Round )\n",
    "\n",
    "\tdf['mean'] = clc_mean(df['Open'] , std_len)\n",
    "\n",
    "\tdf['buy'] = np.where( (df['Open'] > clc_mean(df['Open'],mean_len).shift(1)) & (df['cadle-type'] >= .65), 1 ,0 )\n",
    "\n",
    "\tdf['sell'] = np.where( (df['Open'] < clc_mean(df['Open'],mean_len).shift(1)) & (abs(df['cadle-type']) >= .65)  , 1 ,0 )\n",
    "\n",
    "\tdf['hold'] = np.where(df['buy'] == df['sell'], 1, 0)\n",
    "\n",
    "\t# df['action'] = np.where(buyers == 1, 1,0)\n",
    "\n",
    "\tdf = df.dropna(axis=0)\n",
    "\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1684278986484,
     "user": {
      "displayName": "A H Sh",
      "userId": "16181755643368908406"
     },
     "user_tz": -210
    },
    "id": "VN0JOp9crBxz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-04-16 04:30:00</th>\n",
       "      <td>3264.93</td>\n",
       "      <td>3266.70</td>\n",
       "      <td>3256.08</td>\n",
       "      <td>3265.71</td>\n",
       "      <td>1258</td>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-16 04:45:00</th>\n",
       "      <td>3265.70</td>\n",
       "      <td>3271.47</td>\n",
       "      <td>3265.41</td>\n",
       "      <td>3270.23</td>\n",
       "      <td>1053</td>\n",
       "      <td>5.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-16 05:00:00</th>\n",
       "      <td>3270.64</td>\n",
       "      <td>3275.35</td>\n",
       "      <td>3269.00</td>\n",
       "      <td>3271.31</td>\n",
       "      <td>1187</td>\n",
       "      <td>4.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-16 05:15:00</th>\n",
       "      <td>3271.37</td>\n",
       "      <td>3273.08</td>\n",
       "      <td>3269.88</td>\n",
       "      <td>3271.71</td>\n",
       "      <td>940</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-16 05:30:00</th>\n",
       "      <td>3271.65</td>\n",
       "      <td>3274.14</td>\n",
       "      <td>3268.86</td>\n",
       "      <td>3269.35</td>\n",
       "      <td>1002</td>\n",
       "      <td>2.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Open     High      Low    Close  Volume  diff\n",
       "Date                                                                 \n",
       "2025-04-16 04:30:00  3264.93  3266.70  3256.08  3265.71    1258  1.77\n",
       "2025-04-16 04:45:00  3265.70  3271.47  3265.41  3270.23    1053  5.77\n",
       "2025-04-16 05:00:00  3270.64  3275.35  3269.00  3271.31    1187  4.71\n",
       "2025-04-16 05:15:00  3271.37  3273.08  3269.88  3271.71     940  1.71\n",
       "2025-04-16 05:30:00  3271.65  3274.14  3268.86  3269.35    1002  2.49"
      ]
     },
     "execution_count": 1061,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = creat_data(df)\n",
    "\n",
    "# df.tail()\n",
    "\n",
    "data = df[\n",
    "\t\t\t\t\t['Open', 'High', 'Low' , 'Close', 'Volume', 'diff' ]\n",
    "\t\t\t\t\t]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MarketEnv(gym.Env):\n",
    "\tmetadata = {\"render_modes\": [\"human\"], \"render_fps\": 4}\n",
    "\n",
    "\tdef __init__(self, df: pd.DataFrame, win_size: int):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.df = df.reset_index(drop=True).astype(np.float32)\n",
    "\t\tself.win_size = win_size\n",
    "\t\tself.num_features = df.shape[1]\n",
    "\t\tself.current_step = self.win_size\n",
    "\t\tself.max_steps = len(df) - win_size - 1\n",
    "\t\tself.step_count : int = 0\n",
    "\t\tself.current_position : int = 0\n",
    "\t\tself.reward : float = 0.\n",
    "\t\tself.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
    "\t\tself.observation_space = spaces.Box(\n",
    "\t\t\tlow=-np.inf,\n",
    "\t\t\thigh=np.inf,\n",
    "\t\t\tshape=(win_size, self.num_features),\n",
    "\t\t\tdtype=np.float32\n",
    "\t\t)\n",
    "\t\tself.state : np.ndarray\n",
    "\n",
    "\tdef reset(self, *, seed=None, options=None):\n",
    "\t\tsuper().reset(seed=seed)\n",
    "\t\tself.current_step = self.win_size\n",
    "\t\tself.step_count = 0\n",
    "\t\tself.current_position = 0\n",
    "\t\tself.state = self._get_observation()\n",
    "\t\t# print(f\"state\\n{self.state}\")\n",
    "\t\treturn self.state, {}\n",
    "\n",
    "\tdef _get_observation(self):\n",
    "\t\twindow = self.df.iloc[self.current_step - self.win_size : self.current_step]\n",
    "\t\treturn window.to_numpy()\n",
    "\n",
    "\tdef step(self, action : int, margin : float):\n",
    "\n",
    "\t\t# action += 1\n",
    "\t\tmatch action:\n",
    "\t\t\tcase  1:\n",
    "\t\t\t\taction = 1\n",
    "\t\t\tcase 2:\n",
    "\t\t\t\taction = -1\n",
    "\t\t\tcase 3:\n",
    "\t\t\t\taction = 0\n",
    "\t\t# State:\n",
    "\t\t# O: 0 | H: 1 | L: 2 | C: 3 | V: 4 | D: 5 |\n",
    "\t\tself.reward = self.state[:,5].sum() * (action )\n",
    "\t\t# print(self.reward, action )\n",
    "\t\t# print(f\"reward\\n{self.reward}\")\n",
    "\t\tself.current_step += 1\n",
    "\t\tself.step_count += 1\n",
    "\t\tself.current_position = action # type: ignore\n",
    "\t\tterminated = False\n",
    "\t\ttruncated = self.step_count >= self.max_steps\n",
    "\t\tself.state = self._get_observation()\n",
    "\n",
    "\t\tinfo = {}\n",
    "\t\treturn self.state, self.reward , terminated, truncated, info\n",
    "\n",
    "\tdef render(self, mode=\"human\"):\n",
    "\t\tprint(f\"Step: {self.step_count}, Reward: {self.reward:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Actor(nn.Module):\n",
    "\tdef __init__(self, win_size , n_feature):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.norm_all = nn.LayerNorm(n_feature)\n",
    "\t\t\n",
    "\t\tself.i_know = nn.LSTM(input_size=n_feature, \n",
    "\t\t\t\t\t\thidden_size=n_feature,\n",
    "\t\t\t\t\t\t  num_layers= 128,\n",
    "\t\t\t\t\t\t  batch_first=True)\n",
    "\t\t\n",
    "\t\tself.i_see = nn.Sequential(\n",
    "\t\t\tnn.Conv1d(in_channels=win_size, out_channels=win_size, kernel_size=3, padding='same'),\n",
    "\t\t\tnn.BatchNorm1d(win_size),\n",
    "\t\t\tnn.ReLU()\n",
    "\t\t\t)\n",
    "\n",
    "\t\tself.i_decide = nn.Sequential(\n",
    "\t\t\tnn.Flatten(),\n",
    "\t\t\t# nn.LayerNorm(input_dim),\n",
    "\t\t\tnn.Linear(win_size * n_feature, 128), # fc1\n",
    "\t\t\tnn.LeakyReLU(),\n",
    "\t\t\tnn.Linear(128, 128), # fc2\n",
    "\t\t\tnn.LeakyReLU(),\n",
    "\t\t\tnn.Linear(128, 3), # out\n",
    "\t\t\tnn.Softmax()         \n",
    "\t\t)\n",
    "\n",
    "\n",
    "\tdef forward(self, X: Tensor) -> Tensor:\n",
    "\n",
    "\t\tx : Tensor = self.norm_all(X).unsqueeze(0)\n",
    "\t\t# print(x.shape)\n",
    "\n",
    "\t\tiknow,_ = self.i_know(x)\n",
    "\n",
    "\t\tisee : Tensor = self.i_see(x)\n",
    "\t\t# print(isee.shape, iknow.shape)\n",
    "\t\twhathpend = iknow.tanh() + isee\n",
    "\t\t# print(whathpend.shape)\n",
    "\t\t# print(whathpend.flatten().shape)\n",
    "\n",
    "\t\tout = self.i_decide(whathpend)\n",
    "\n",
    "\t\treturn out\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "\tdef __init__(self, state_dim: int, action_dim: int):\n",
    "\t\tsuper().__init__()\n",
    "\t\tinput_dim = state_dim + action_dim\n",
    "\n",
    "\t\tself.fc = nn.Sequential(\n",
    "\t\t\tnn.LayerNorm(input_dim),\n",
    "\t\t\tnn.Linear(input_dim, 256),\n",
    "\t\t\tnn.InstanceNorm1d(256),\n",
    "\t\t\tnn.LeakyReLU(),\n",
    "\t\t\tnn.Linear(256, 128),\n",
    "\t\t\tnn.InstanceNorm1d(128),\n",
    "\t\t\tnn.LeakyReLU(),\n",
    "\t\t\tnn.Linear(128, 1)  # Q-value output\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, state: Tensor, action: Tensor) -> Tensor:\n",
    "\t\t# action = action.unsqueeze(0) if action.ndim == 1 else action\n",
    "\t\t# print(state.shape, action.shape)\n",
    "\n",
    "\t\t# if state.ndim == 1:\n",
    "\t\t# \t# batch mode\n",
    "\t\t# \tx = torch.cat([state, action], dim=1)\n",
    "\t\t# else:\n",
    "\t\t# \t# single sample mode\n",
    "\t\t# \tx = torch.cat([state, action], dim=0)\n",
    "\t\tx = torch.cat([state.flatten(), action.unsqueeze(0)]).unsqueeze(0)\n",
    "\t\tvalue: Tensor = self.fc(x)\n",
    "\t\treturn value\n",
    "\n",
    "\n",
    "# تبدیل observation به بردار 1D برای ورودی شبکه\n",
    "def preprocess_obs(obs : np.ndarray | Tensor) -> torch.Tensor:\n",
    "\treturn torch.tensor(obs, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5395.000000</td>\n",
       "      <td>5395.000000</td>\n",
       "      <td>5395.000000</td>\n",
       "      <td>5395.000000</td>\n",
       "      <td>5395.000000</td>\n",
       "      <td>5395.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3322.211231</td>\n",
       "      <td>3325.043720</td>\n",
       "      <td>3319.199804</td>\n",
       "      <td>3322.209398</td>\n",
       "      <td>983.464690</td>\n",
       "      <td>2.832489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>55.558108</td>\n",
       "      <td>55.443088</td>\n",
       "      <td>55.595445</td>\n",
       "      <td>55.556601</td>\n",
       "      <td>248.673301</td>\n",
       "      <td>2.831925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3126.920000</td>\n",
       "      <td>3132.400000</td>\n",
       "      <td>3120.780000</td>\n",
       "      <td>3126.940000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3294.825000</td>\n",
       "      <td>3297.890000</td>\n",
       "      <td>3292.210000</td>\n",
       "      <td>3294.845000</td>\n",
       "      <td>839.000000</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3326.500000</td>\n",
       "      <td>3329.100000</td>\n",
       "      <td>3323.780000</td>\n",
       "      <td>3326.510000</td>\n",
       "      <td>991.000000</td>\n",
       "      <td>2.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3357.625000</td>\n",
       "      <td>3360.565000</td>\n",
       "      <td>3355.080000</td>\n",
       "      <td>3357.705000</td>\n",
       "      <td>1146.000000</td>\n",
       "      <td>3.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3497.360000</td>\n",
       "      <td>3499.980000</td>\n",
       "      <td>3489.180000</td>\n",
       "      <td>3497.330000</td>\n",
       "      <td>1966.000000</td>\n",
       "      <td>35.140000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open         High          Low        Close       Volume  \\\n",
       "count  5395.000000  5395.000000  5395.000000  5395.000000  5395.000000   \n",
       "mean   3322.211231  3325.043720  3319.199804  3322.209398   983.464690   \n",
       "std      55.558108    55.443088    55.595445    55.556601   248.673301   \n",
       "min    3126.920000  3132.400000  3120.780000  3126.940000   106.000000   \n",
       "25%    3294.825000  3297.890000  3292.210000  3294.845000   839.000000   \n",
       "50%    3326.500000  3329.100000  3323.780000  3326.510000   991.000000   \n",
       "75%    3357.625000  3360.565000  3355.080000  3357.705000  1146.000000   \n",
       "max    3497.360000  3499.980000  3489.180000  3497.330000  1966.000000   \n",
       "\n",
       "              diff  \n",
       "count  5395.000000  \n",
       "mean      2.832489  \n",
       "std       2.831925  \n",
       "min       0.000000  \n",
       "25%       0.910000  \n",
       "50%       2.050000  \n",
       "75%       3.820000  \n",
       "max      35.140000  "
      ]
     },
     "execution_count": 1064,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert not data.isnull().any().any(), \"NaN exists in dataframe!\"\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x22445612690>"
      ]
     },
     "execution_count": 1065,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs tensor([[0.3325, 0.3402, 0.3274]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 1, Reward: -16.4500\n",
      "probs tensor([[0.3326, 0.3412, 0.3263]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 2, Reward: -15.7100\n",
      "probs tensor([[0.3323, 0.3404, 0.3274]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 3, Reward: -15.5700\n",
      "probs tensor([[0.3319, 0.3410, 0.3272]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 4, Reward: -15.2100\n",
      "probs tensor([[0.3321, 0.3408, 0.3272]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 5, Reward: -14.4800\n",
      "probs tensor([[0.3320, 0.3409, 0.3270]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 6, Reward: -17.4900\n",
      "probs tensor([[0.3321, 0.3407, 0.3272]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 7, Reward: -18.6900\n",
      "probs tensor([[0.3316, 0.3405, 0.3279]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 8, Reward: -13.0600\n",
      "probs tensor([[0.3315, 0.3414, 0.3272]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 9, Reward: -17.1400\n",
      "probs tensor([[0.3315, 0.3407, 0.3278]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 10, Reward: -24.5100\n",
      "probs tensor([[0.3309, 0.3408, 0.3282]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 11, Reward: -24.3800\n",
      "probs tensor([[0.3320, 0.3413, 0.3267]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 12, Reward: -25.4700\n",
      "probs tensor([[0.3322, 0.3408, 0.3269]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 13, Reward: -28.1200\n",
      "probs tensor([[0.3318, 0.3411, 0.3271]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 14, Reward: -21.9300\n",
      "probs tensor([[0.3314, 0.3407, 0.3279]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 15, Reward: -14.1600\n",
      "probs tensor([[0.3318, 0.3415, 0.3267]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 16, Reward: -11.7000\n",
      "probs tensor([[0.3322, 0.3407, 0.3271]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 17, Reward: -13.1700\n",
      "probs tensor([[0.3321, 0.3412, 0.3266]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 18, Reward: -13.6900\n",
      "probs tensor([[0.3319, 0.3405, 0.3275]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 19, Reward: -17.6300\n",
      "probs tensor([[0.3323, 0.3415, 0.3263]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 20, Reward: -17.8200\n",
      "probs tensor([[0.3324, 0.3401, 0.3274]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 21, Reward: -15.1200\n",
      "probs tensor([[0.3329, 0.3413, 0.3258]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 22, Reward: -16.0900\n",
      "probs tensor([[0.3327, 0.3405, 0.3268]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 23, Reward: -22.3900\n",
      "probs tensor([[0.3322, 0.3410, 0.3269]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 24, Reward: -24.2500\n",
      "probs tensor([[0.3319, 0.3410, 0.3272]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 25, Reward: -24.7500\n",
      "probs tensor([[0.3322, 0.3409, 0.3268]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 26, Reward: -42.0100\n",
      "probs tensor([[0.3330, 0.3400, 0.3269]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 27, Reward: -37.0700\n",
      "probs tensor([[0.3339, 0.3402, 0.3259]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 28, Reward: -31.3800\n",
      "probs tensor([[0.3338, 0.3395, 0.3268]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 29, Reward: -25.3100\n",
      "probs tensor([[0.3331, 0.3405, 0.3263]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 30, Reward: -27.1300\n",
      "probs tensor([[0.3327, 0.3408, 0.3265]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 31, Reward: -12.1000\n",
      "probs tensor([[0.3324, 0.3408, 0.3267]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 32, Reward: -15.9100\n",
      "probs tensor([[0.3321, 0.3407, 0.3272]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 33, Reward: -13.3800\n",
      "probs tensor([[0.3320, 0.3410, 0.3271]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 34, Reward: -13.8400\n",
      "probs tensor([[0.3320, 0.3410, 0.3270]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 35, Reward: -11.9500\n",
      "probs tensor([[0.3317, 0.3410, 0.3272]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 36, Reward: -12.4100\n",
      "probs tensor([[0.3316, 0.3408, 0.3275]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 37, Reward: -16.4500\n",
      "probs tensor([[0.3317, 0.3413, 0.3270]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 38, Reward: -25.9200\n",
      "probs tensor([[0.3320, 0.3411, 0.3269]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 39, Reward: -26.3800\n",
      "probs tensor([[0.3317, 0.3404, 0.3279]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 40, Reward: -26.9700\n",
      "probs tensor([[0.3323, 0.3415, 0.3262]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 41, Reward: -29.6600\n",
      "probs tensor([[0.3326, 0.3407, 0.3267]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 42, Reward: -21.5500\n",
      "probs tensor([[0.3320, 0.3407, 0.3273]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 43, Reward: -14.4300\n",
      "probs tensor([[0.3323, 0.3411, 0.3266]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 44, Reward: -14.1800\n",
      "probs tensor([[0.3326, 0.3409, 0.3265]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 45, Reward: -14.1700\n",
      "probs tensor([[0.3327, 0.3404, 0.3270]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 46, Reward: -26.6000\n",
      "probs tensor([[0.3329, 0.3406, 0.3265]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 47, Reward: -33.7900\n",
      "probs tensor([[0.3331, 0.3402, 0.3267]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 48, Reward: -35.6400\n",
      "probs tensor([[0.3332, 0.3396, 0.3272]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n",
      "Step: 49, Reward: -34.8000\n",
      "probs tensor([[0.3335, 0.3403, 0.3262]], grad_fn=<SoftmaxBackward0>)\n",
      "action 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1066]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# target critic Q-value\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \tnext_action = torch.argmax(\u001b[43mactor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m)\u001b[49m+\u001b[32m1\u001b[39m)\n\u001b[32m     54\u001b[39m \t\u001b[38;5;66;03m# print(next_action, )\u001b[39;00m\n\u001b[32m     55\u001b[39m \ttarget_q = reward + gamma * critic(next_state, next_action) * (\u001b[32m1.0\u001b[39m - \u001b[38;5;28mfloat\u001b[39m(done))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nemo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nemo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1063]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mActor.forward\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     37\u001b[39m x : Tensor = \u001b[38;5;28mself\u001b[39m.norm_all(X).unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m iknow,_ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mi_know\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m isee : Tensor = \u001b[38;5;28mself\u001b[39m.i_see(x)\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# print(isee.shape, iknow.shape)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nemo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nemo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nemo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1124\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1121\u001b[39m         hx = \u001b[38;5;28mself\u001b[39m.permute_hidden(hx, sorted_indices)\n\u001b[32m   1123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m     result = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1128\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1136\u001b[39m     result = _VF.lstm(\n\u001b[32m   1137\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1138\u001b[39m         batch_sizes,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1145\u001b[39m         \u001b[38;5;28mself\u001b[39m.bidirectional,\n\u001b[32m   1146\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "window_size = 5\n",
    "\n",
    "env = MarketEnv(df=data, win_size=window_size)\n",
    "obs, _ = env.reset()\n",
    "\n",
    "actor: Actor   = Actor (win_size=window_size, n_feature=env.num_features )\n",
    "critic: Critic = Critic(state_dim=window_size * env.num_features, action_dim=1)\n",
    "\n",
    "optimizerA = optim.Adam(actor.parameters(), lr=1e-3)\n",
    "optimizerC = optim.Adam(critic.parameters(), lr=1e-3)\n",
    "\n",
    "gamma = 0.99\n",
    "num_episodes = 10\n",
    "max_steps = 1_00\n",
    "reward_to_episodes = []\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "\tactor.train()\n",
    "\tcritic.train()\n",
    "\t\n",
    "\tobs, _ = env.reset()\n",
    "\tdone = False\n",
    "\ttotal_reward = 0\n",
    "\t\n",
    "\tfor step in range(max_steps):\n",
    "\t\tstate: Tensor = preprocess_obs(obs)\n",
    "\t\t# print(f\"state\\n{state}\")\n",
    "\t\t# Choosing Act\n",
    "\t\taction_probs: Tensor = actor(state)\n",
    "\t\tprint(f\"probs {action_probs}\")\n",
    "\t\t# dist =  torch.distributions.Categorical(action_probs)\n",
    "\t\t# print(f\"dist {dist.logits}\")\n",
    "\t\taction: Tensor = torch.argmax(action_probs) +1 #dist.sample()\n",
    "\t\tprint(f\"action {action}\")\n",
    "\t\tmargin: Tensor = action_probs.max().round(decimals=2)\n",
    "\t\t# print(f\"margin {margin}\")\n",
    "\t\t\n",
    "\t\t# اجرای عمل در محیط\n",
    "\t\tnext_obs, reward, terminated, truncated, info = env.step(action.item(), margin.item())\n",
    "\t\tdone = terminated or truncated\n",
    "\t\t\n",
    "\t   \n",
    "\t\tnext_state = preprocess_obs(next_obs)\n",
    "\t\t\n",
    "\t\t# محاسبه ارزش حالت فعلی و بعدی\n",
    "\t\t# print(state.shape)\n",
    "\t\tq_val   : Tensor = critic(state,action).detach().requires_grad_()\n",
    "\t\t# print(f\"value {value}\")\n",
    "\t\tnext_q_value: Tensor = critic(next_state,action).detach().requires_grad_()\n",
    "\t\t\n",
    "\t\t# target critic Q-value\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tnext_action = torch.argmax(actor(next_state)+1)\n",
    "\t\t\t# print(next_action, )\n",
    "\t\t\ttarget_q = reward + gamma * critic(next_state, next_action) * (1.0 - float(done))\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t# critic loss\n",
    "\t\tpredicted_q = critic(state, action)\n",
    "\t\tcritic_loss = F.mse_loss(predicted_q, target_q)\n",
    "\n",
    "\t\t\n",
    "\t\t# actor loss\n",
    "\t\t# predicted_action = actor(state)\n",
    "\t\tactor_loss: Tensor = -critic(state, action).mean().detach().requires_grad_()\n",
    "\t\t\n",
    "\t\t# بهروزرسانی Critic\n",
    "\t\toptimizerC.zero_grad()\n",
    "\t\tcritic_loss.backward(retain_graph=True)\n",
    "\t\toptimizerC.step()\n",
    "\t\t\n",
    "\t\t# بهروزرسانی Actor\n",
    "\t\toptimizerA.zero_grad()\n",
    "\t\tactor_loss.backward(retain_graph=False)\n",
    "\t\toptimizerA.step()\n",
    "\t\t\n",
    "\t\ttotal_reward += reward.item()\n",
    "\t\tobs = next_obs\n",
    "\t\t# print(\"check\")\n",
    "\t\tenv.render()\n",
    "\t\tif done:\n",
    "\t\t\tbreak\n",
    "\treward_to_episodes.append(total_reward)\n",
    "\tprint(f\"Episode {episode} | Total Reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.lineplot({\"reward\": reward_to_episodes})\n",
    "plt.title(\"total reward for each episode\")\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel(\"Rewards\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_tensor = torch.tensor(data.to_numpy(), dtype=torch.float).reshape(-1, 5,6)\n",
    "# print(data_tensor)\n",
    "\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "\tactor.eval()\n",
    "\tfor state in data_tensor:\n",
    "\t\tOutput = actor(state.flatten())\n",
    "\t\tOutput = torch.argmax(Output)\n",
    "\t\tlabels.append(Output)\n",
    "\n",
    "labels = torch.tensor(labels)\n",
    "print(labels)\n",
    "print(Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(labels), labels.shape , data_tensor.shape, data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "provenance": [
    {
     "file_id": "18eyr28BgWOOex2Eeg6rlBUbF4urSysI1",
     "timestamp": 1684274748287
    }
   ],
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
